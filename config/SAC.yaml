discrete: False

policy:
  learning_rate: 0.0003
  gamma: 0.9
  buffer_size: 50000
  learning_starts: 5000
  batch_size: 128
  target_update_interval: 1
  policy_kwargs: 'empty_dict'
  verbose: 1

  # [plain, entropy, action, next_action, state]
  # [0.0,  0.05,    0.05,   0.1,         0.05 ]

  method: 'entropy'
  ent_coef: 'auto'

buffer:
  prioritized_ensemble: True

learn:
  total_timesteps: 5000000
  log_interval: 100


